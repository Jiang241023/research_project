{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592f668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved one-sample box plot → /home/RUS_CIP/st186731/research_project/hybrid_approach/evaluation_output/op20/op20_grit_like_fullsamples_15epoch_alpha1_beta1_withlap_@_sample_16045_pernode_magnitude.png\n",
      "[1/1] processed\n",
      "\n",
      "--- Springback stats (TOTAL across all nodes) ---\n",
      "Ground_Truth : mean=0.2792,  max=1.2861,  std=0.3840\n",
      "Prediction   : mean=0.2321, max=1.3652, std=0.3049\n",
      "Difference(L2 per-node) : mean=0.0805,  max=0.5140,  std=0.0946\n",
      "\n",
      "--- Chamfer stats (L2, TOTAL) ---\n",
      "(GT→Pred): mean=0.080517, max=0.514048, std=0.094479\n",
      "(Pred→GT): mean=0.080546, max=0.514048, std=0.094583\n",
      "Symmetric        : 0.161063\n",
      "\n",
      "Processed 1/1 files (skipped=0)\n",
      "[OK] Wrote totals CSV → /home/RUS_CIP/st186731/research_project/hybrid_approach/evaluation_output/op20/op20_grit_like_fullsamples_15epoch_alpha1_beta1_withlap_@_dataset_totals.csv\n",
      "[OK] Wrote per-sample CSV → /home/RUS_CIP/st186731/research_project/hybrid_approach/evaluation_output/op20/op20_grit_like_fullsamples_15epoch_alpha1_beta1_withlap_@_per_sample.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from DDACSDataset import DDACSDataset\n",
    "from utils_DDACS import extract_mesh, extract_point_springback\n",
    "from scipy.spatial import cKDTree as KDTree\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Utils\n",
    "# -------------------------\n",
    "def find_h5_by_id(dataset, sid):\n",
    "    \"\"\"Return (sim_id, metadata, h5_path) for the given string/int sample id.\"\"\"\n",
    "    sid = str(sid)\n",
    "    for i in range(len(dataset)):\n",
    "        sim_id, meta, h5_path = dataset[i]\n",
    "        if str(sim_id) == sid:\n",
    "            return sim_id, meta, h5_path\n",
    "    raise FileNotFoundError(f\"Sample id {sid} not found in dataset\")\n",
    "\n",
    "\n",
    "def nearest_neighbor_distances(query_points, reference_points):\n",
    "    \"\"\"Per-point NN distances from query_points to reference_points (L2).\n",
    "       KDTree: 'k-dimensional tree.'\n",
    "    \"\"\"\n",
    "    tree = KDTree(reference_points)\n",
    "    distances, _ = tree.query(query_points, k=1, workers=-1)\n",
    "    return distances.astype(np.float64)\n",
    "\n",
    "\n",
    "class RunningStats:\n",
    "    \"\"\"Streaming mean/std/max over arbitrarily many 1D/ND arrays.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.total_count = 0\n",
    "        self.running_sum = 0.0\n",
    "        self.running_sum_of_squares = 0.0\n",
    "        self.running_max = -np.inf\n",
    "\n",
    "    def update(self, values):\n",
    "        values = np.asarray(values, dtype=np.float64).ravel()  # 1D view if possible\n",
    "        if values.size == 0:\n",
    "            return\n",
    "        self.total_count += values.size\n",
    "        self.running_sum += float(values.sum())\n",
    "        self.running_sum_of_squares += float((values ** 2).sum())\n",
    "        current_batch_max = float(values.max())\n",
    "        if current_batch_max > self.running_max:\n",
    "            self.running_max = current_batch_max\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        count = self.total_count\n",
    "        if count <= 0:\n",
    "            return float(\"nan\")\n",
    "        return self.running_sum / count\n",
    "\n",
    "    @property\n",
    "    def std(self):\n",
    "        if self.total_count == 0:\n",
    "            return float(\"nan\")\n",
    "        current_mean = self.mean\n",
    "        current_variance = max(0.0, self.running_sum_of_squares / self.total_count - current_mean ** 2)\n",
    "        return current_variance ** 0.5\n",
    "\n",
    "    @property\n",
    "    def max(self):\n",
    "        return self.running_max\n",
    "\n",
    "\n",
    "def scan_prediction_files(pred_dir):\n",
    "    \"\"\"Return list of (sample_id, full_path) for *_pred_node_displacement.npy files.\"\"\"\n",
    "    pattern = re.compile(r\"^(\\d+)_pred_node_displacement\\.npy$\")\n",
    "    out = []\n",
    "    for name in os.listdir(pred_dir):\n",
    "        match = pattern.match(name)\n",
    "        if match:\n",
    "            out.append((match.group(1), os.path.join(pred_dir, name)))\n",
    "    out.sort(key=lambda t: int(t[0]))  # numeric sort: 2, 10, 100 ...\n",
    "    return out\n",
    "\n",
    "\n",
    "def summarize(values):\n",
    "    \"\"\"Return (mean, max, std) for any array-like; returns NaNs if empty.\"\"\"\n",
    "    values = np.asarray(values, dtype=np.float64).ravel()\n",
    "    if values.size == 0:\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "    return (float(values.mean()), float(values.max()), float(values.std()))\n",
    "\n",
    "\n",
    "def boxplot_one_sample(data_dict, title, filename, save_dir, whis=(0, 100), ylabel=None):\n",
    "    \"\"\"Save a box plot for a single sample's per-node distributions.\"\"\"\n",
    "    import matplotlib\n",
    "    matplotlib.use(\"Agg\")  # headless servers\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    labels = list(data_dict.keys())\n",
    "    data = [np.asarray(v, dtype=float).ravel() for v in data_dict.values()]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 5), dpi=150)\n",
    "    ax.boxplot(\n",
    "        data,\n",
    "        tick_labels=labels,\n",
    "        whis=(0, 100),\n",
    "        showmeans=False,\n",
    "        meanline=True,\n",
    "        vert=True,\n",
    "        patch_artist=False,\n",
    "        showfliers=False       \n",
    "    )\n",
    "    ax.grid(True, axis='y', linestyle='--', alpha=0.4)\n",
    "    ax.set_title(title)\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel)\n",
    "    fig.tight_layout()\n",
    "    out_path = save_dir / filename\n",
    "    fig.savefig(out_path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"[OK] Saved one-sample box plot → {out_path}\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Main\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # ---- Config ----\n",
    "    operation   = 20    # 10 or 20\n",
    "    timestep    = 0     # 2 (for OP10) or 0 (for OP20), per your dataset\n",
    "    pred_dir    = \"/home/RUS_CIP/st186731/research_project/hybrid_approach/grit_like_and_graphormer_like/prediction/ddacs-node-regression/grit_like_op20_grit_like_fullsamples_15epoch_alpha1_beta1_withlap\"\n",
    "    data_dir    = Path(\"/mnt/data/darus/\")\n",
    "    experiment_name = \"op20_grit_like_fullsamples_15epoch_alpha1_beta1_withlap_@\"\n",
    "\n",
    "    # NEW: process only one sample (set to a string ID), or None for all\n",
    "    CHECK_SAMPLE_ID = \"16045\"         # e.g., \"16039\"; set to None to process all\n",
    "    MAKE_SINGLE_SAMPLE_PLOTS = True   # per-node boxplots for that sample\n",
    "\n",
    "    # Saving\n",
    "    WRITE_CSV = True\n",
    "    WRITE_SAMPLES_CSV = True\n",
    "    save_dir = Path(\"/home/RUS_CIP/st186731/research_project/hybrid_approach/evaluation_output/op20\")\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    totals_csv_path = save_dir / f\"{experiment_name}_dataset_totals.csv\"\n",
    "    samples_csv_path = save_dir / f\"{experiment_name}_per_sample.csv\"\n",
    "\n",
    "    # ---- Load dataset index & predictions ----\n",
    "    dataset = DDACSDataset(data_dir, \"h5\")\n",
    "    pairs = scan_prediction_files(pred_dir)\n",
    "\n",
    "    # Filter to one sample if requested; try fallback exact filename if scan misses it\n",
    "    if CHECK_SAMPLE_ID is not None:\n",
    "        pairs = [(sid, path) for (sid, path) in pairs if str(sid) == str(CHECK_SAMPLE_ID)]\n",
    "        if not pairs:\n",
    "            single_path = os.path.join(pred_dir, f\"{CHECK_SAMPLE_ID}_pred_node_displacement.npy\")\n",
    "            if os.path.isfile(single_path):\n",
    "                pairs = [(str(CHECK_SAMPLE_ID), single_path)]\n",
    "            else:\n",
    "                raise SystemExit(f\"No prediction file found for sample {CHECK_SAMPLE_ID} in: {pred_dir}\")\n",
    "\n",
    "    if not pairs:\n",
    "        raise SystemExit(f\"No *_pred_node_displacement.npy files in: {pred_dir}\")\n",
    "\n",
    "    # ---- Pooled stats across ALL nodes in ALL processed samples ----\n",
    "    gt_stats   = RunningStats()\n",
    "    pred_stats = RunningStats()\n",
    "    diff_stats = RunningStats()\n",
    "    cham_gt_pred = RunningStats()\n",
    "    cham_pred_gt = RunningStats()\n",
    "    processed = 0\n",
    "    skipped = 0\n",
    "\n",
    "    sample_rows = []\n",
    "\n",
    "    # ---- Process each (sample_id, prediction_path) ----\n",
    "    for k, (sid, path) in enumerate(pairs, 1):\n",
    "        try:\n",
    "            # Locate H5\n",
    "            sim_id, metadata, h5_path = find_h5_by_id(dataset, sid)\n",
    "\n",
    "            # Mesh + ground truth\n",
    "            node_coords, triangles = extract_mesh(\n",
    "                h5_path, operation=operation, component='blank', timestep=timestep\n",
    "            )\n",
    "            final_coords_gt, disp_gt = extract_point_springback(h5_path, operation=operation)\n",
    "\n",
    "            # Prediction\n",
    "            disp_pred = np.load(path)\n",
    "            if disp_pred.shape != disp_gt.shape:\n",
    "                raise ValueError(f\"shape mismatch for id={sid}: pred {disp_pred.shape} vs gt {disp_gt.shape}\")\n",
    "\n",
    "            # Magnitudes and differences\n",
    "            mag_gt   = np.linalg.norm(disp_gt,   axis=1)\n",
    "            mag_pred = np.linalg.norm(disp_pred, axis=1)\n",
    "            diff_mag = np.linalg.norm(disp_pred - disp_gt, axis=1)\n",
    "\n",
    "            # Final positions and Chamfer (NN L2 both directions)\n",
    "            final_coords_pred = node_coords + disp_pred\n",
    "            distances_gt_pred = nearest_neighbor_distances(final_coords_gt,  final_coords_pred)  # GT→Pred\n",
    "            distances_pred_gt = nearest_neighbor_distances(final_coords_pred, final_coords_gt)   # Pred→GT\n",
    "\n",
    "            # Update pooled stats\n",
    "            gt_stats.update(mag_gt)\n",
    "            pred_stats.update(mag_pred)\n",
    "            diff_stats.update(diff_mag)\n",
    "            cham_gt_pred.update(distances_gt_pred)\n",
    "            cham_pred_gt.update(distances_pred_gt)\n",
    "\n",
    "            # Per-sample summary row (for CSV)\n",
    "            gt_mean_s, gt_max_s, gt_std_s = summarize(mag_gt)\n",
    "            pred_mean_s, pred_max_s, pred_std_s = summarize(mag_pred)\n",
    "            diff_mean_s, diff_max_s, diff_std_s = summarize(diff_mag)\n",
    "            cham_gt_pred_mean_s, cham_gt_pred_max_s, cham_gt_pred_std_s = summarize(distances_gt_pred)\n",
    "            cham_pred_gt_mean_s, cham_pred_gt_max_s, cham_pred_gt_std_s = summarize(distances_pred_gt)\n",
    "            cham_sym = cham_gt_pred_mean_s + cham_pred_gt_mean_s\n",
    "\n",
    "            sample_rows.append([\n",
    "                int(sid),\n",
    "                gt_mean_s, gt_max_s, gt_std_s,\n",
    "                pred_mean_s, pred_max_s, pred_std_s,\n",
    "                diff_mean_s, diff_max_s, diff_std_s,\n",
    "                cham_gt_pred_mean_s, cham_gt_pred_max_s, cham_gt_pred_std_s,\n",
    "                cham_pred_gt_mean_s, cham_pred_gt_max_s, cham_pred_gt_std_s,\n",
    "                cham_sym\n",
    "            ])\n",
    "\n",
    "            # NEW: per-node box plots for the checked sample\n",
    "            if CHECK_SAMPLE_ID is not None and str(sid) == str(CHECK_SAMPLE_ID) and MAKE_SINGLE_SAMPLE_PLOTS:\n",
    "                boxplot_one_sample(\n",
    "                    {\"Ground Truth\": mag_gt, \"Prediction \": mag_pred, \"Difference\": diff_mag},\n",
    "                    f\"{experiment_name}: sample {sid} — Springback magnitude (per-node)\",\n",
    "                    f\"{experiment_name}_sample_{sid}_pernode_magnitude.png\",\n",
    "                    save_dir=save_dir,\n",
    "                    ylabel=\"Displacement\"\n",
    "                )\n",
    "\n",
    "            processed += 1\n",
    "\n",
    "            # Optional progress\n",
    "            if (k % 10 == 0) or (k == len(pairs)):\n",
    "                print(f\"[{k}/{len(pairs)}] processed\")\n",
    "\n",
    "        except Exception as e:\n",
    "            skipped += 1\n",
    "            print(f\"[WARN] Skipping id={sid}: {e}\")\n",
    "\n",
    "    # ---- Dataset-level (pooled) totals ----\n",
    "    chamfer_symmetric_mean = cham_gt_pred.mean + cham_pred_gt.mean\n",
    "\n",
    "    print(\"\\n--- Springback stats (TOTAL across all nodes) ---\")\n",
    "    print(f\"Ground_Truth : mean={gt_stats.mean:.4f},  max={gt_stats.max:.4f},  std={gt_stats.std:.4f}\")\n",
    "    print(f\"Prediction   : mean={pred_stats.mean:.4f}, max={pred_stats.max:.4f}, std={pred_stats.std:.4f}\")\n",
    "    print(f\"Difference(L2 per-node) : mean={diff_stats.mean:.4f},  max={diff_stats.max:.4f},  std={diff_stats.std:.4f}\")\n",
    "\n",
    "    print(\"\\n--- Chamfer stats (L2, TOTAL) ---\")\n",
    "    print(f\"(GT→Pred): mean={cham_gt_pred.mean:.6f}, max={cham_gt_pred.max:.6f}, std={cham_gt_pred.std:.6f}\")\n",
    "    print(f\"(Pred→GT): mean={cham_pred_gt.mean:.6f}, max={cham_pred_gt.max:.6f}, std={cham_pred_gt.std:.6f}\")\n",
    "    print(f\"Symmetric        : {chamfer_symmetric_mean:.6f}\")\n",
    "    print(f\"\\nProcessed {processed}/{len(pairs)} files (skipped={skipped})\")\n",
    "\n",
    "    # ---- Write CSVs ----\n",
    "    if WRITE_CSV:\n",
    "        headers = [\n",
    "            \"gt_mean\",\"gt_max\",\"gt_std\",\n",
    "            \"pred_mean\",\"pred_max\",\"pred_std\",\n",
    "            \"diff_mean\",\"diff_max\",\"diff_std\",\n",
    "            \"chamfer_distance_gt_pred_mean\",\"chamfer_distance_gt_pred_max\",\"chamfer_distance_gt_pred_std\",\n",
    "            \"chamfer_distance_pred_gt_mean\",\"chamfer_distance_pred_gt_max\",\"chamfer_distance_pred_gt_std\",\n",
    "            \"chamfer_distance_symmetric\",\"num_files\",\"skipped\"\n",
    "        ]\n",
    "        values = [\n",
    "            gt_stats.mean, gt_stats.max, gt_stats.std,\n",
    "            pred_stats.mean, pred_stats.max, pred_stats.std,\n",
    "            diff_stats.mean, diff_stats.max, diff_stats.std,\n",
    "            cham_gt_pred.mean, cham_gt_pred.max, cham_gt_pred.std,\n",
    "            cham_pred_gt.mean, cham_pred_gt.max, cham_pred_gt.std,\n",
    "            chamfer_symmetric_mean, processed, skipped\n",
    "        ]\n",
    "        with open(totals_csv_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\",\".join(headers) + \"\\n\")\n",
    "            parts = []\n",
    "            for v in values:\n",
    "                if isinstance(v, (float, np.floating)):\n",
    "                    s = f\"{v:.10f}\"\n",
    "                else:\n",
    "                    s = str(v)\n",
    "                parts.append(s)\n",
    "            f.write(\",\".join(parts) + \"\\n\")\n",
    "        print(f\"[OK] Wrote totals CSV → {totals_csv_path}\")\n",
    "\n",
    "    if WRITE_SAMPLES_CSV and len(sample_rows) > 0:\n",
    "        sample_headers = [\n",
    "            \"sample_id\",\n",
    "            \"gt_mean\",\"gt_max\",\"gt_std\",\n",
    "            \"pred_mean\",\"pred_max\",\"pred_std\",\n",
    "            \"diff_mean\",\"diff_max\",\"diff_std\",\n",
    "            \"chamfer_distance_gt_pred_mean\",\"chamfer_distance_gt_pred_max\",\"chamfer_distance_gt_pred_std\",\n",
    "            \"chamfer_distance_pred_gt_mean\",\"chamfer_distance_pred_gt_max\",\"chamfer_distance_pred_gt_std\",\n",
    "            \"chamfer_distance_symmetric\"\n",
    "        ]\n",
    "        with open(samples_csv_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\",\".join(sample_headers) + \"\\n\")\n",
    "            for row in sample_rows:\n",
    "                out = []\n",
    "                for v in row:\n",
    "                    if isinstance(v, (float, np.floating)):\n",
    "                        out.append(f\"{v:.10f}\")\n",
    "                    else:\n",
    "                        out.append(str(v))\n",
    "                f.write(\",\".join(out) + \"\\n\")\n",
    "        print(f\"[OK] Wrote per-sample CSV → {samples_csv_path}\")\n",
    "\n",
    "# Example:\n",
    "# python /home/RUS_CIP/st186731/research_project/hybrid_approach/evaluation/evaluation.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
